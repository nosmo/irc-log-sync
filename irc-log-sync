#!/usr/bin/env python2.7

"""Backup a remote irc session's logdir to a local computer.

Assuming an irssi-like logdir setup using 'autolog_path =
"~/irclogs/$tag/$0.%Y-%m-%d.log";', move files from the remote
directory into a similar directory structure locally. Remove all
remote files but the logfile for the current day (or, worst case
scenario, the current day and the day before assuming a change of day
mid-sync).

"""

import argparse
import datetime
import glob
import json
import os
import subprocess
import tempfile

"""second_dir_behaviour - Behaviour for when a network name ends with
a "2", usually indicating a duplicate connection.

skip - skip the folder altogether
none - treat the folder like any other network
merge - lololololololololo some day. TODO - cat files, merge+sort with
existing files in actual network name? who knows.

"""
DEFAULT_CONFIG = {
    "second_dir_behaviour": "skip"
}

SECOND_DIR_BEHAVIOUR="skip"

def sync_files(remote_host):
    workdir=tempfile.mkdtemp()

    rsync=subprocess.Popen(
        ["/usr/bin/rsync", "--progress", "--partial", "-rtv",
         "--rsh=ssh", "%s:irclogs" % remote_host, workdir],
        stdout=subprocess.PIPE,
        stderr=subprocess.PIPE,
    )
    stdout, stderr = rsync.communicate()
    if rsync.returncode != 0:
        raise Exception("rsync failed with output: %s" % stderr)
    return workdir

def get_files(work_dir, backup_dir):
    file_list = []
    for log_dir in glob.glob("%s/irclogs/*" % work_dir):
        if log_dir.endswith("2"):
            if SECOND_DIR_BEHAVIOUR == "skip":
                print("Skipping second-connection dir %s" % log_dir)
                continue
            elif SECOND_DIR_BEHAVIOUR == "none":
                # Don't do anything, treat the dir as normal
                pass
            elif SECOND_DIR_BEHAVIOUR == "merge":
                #TODO
                raise NotImplementedError

        if os.path.isdir(log_dir):
            network = os.path.split(log_dir)[-1]
            backup_destination = os.path.join(backup_dir, network)
            if not os.path.isdir(backup_destination):
                os.mkdir(backup_destination, 0700)
                print "Backup dir for %s does not exist, creating it" % network

            log_files = [ os.path.split(i)[-1] for i in glob.glob(
                "%s/irclogs/%s/*" % (work_dir, network)) ]
            for log_file in log_files:
                os.rename(os.path.join(log_dir, log_file),
                          os.path.join(backup_destination, log_file))
                print "Moved %s:%s" % (network, log_file)
                file_list.append(os.path.join(network,log_file))
    return file_list

def clean_files(remote_host, user, file_list, now):
    if not file_list:
        print "No files, not removing"
        return
    today_suffix = "%s.log" % now.strftime("%Y-%m-%d")
    rm_cmd = ["rm"] + [ "irclogs/%s" % i for i in file_list if not i.endswith(today_suffix) ]
    full_files_cmd = [ "ssh", "%s@%s" % (user, remote_host), " ".join(rm_cmd) ]

    print full_files_cmd

    remote_cmd = subprocess.Popen(
        full_files_cmd,
        stdout=subprocess.PIPE,
        stderr=subprocess.PIPE,
    )
    stdout, stderr = remote_cmd.communicate()
    print stdout
    if remote_cmd.returncode != 0:
        print "Remote command failed: %s" % stderr

if __name__ == "__main__":

    config = DEFAULT_CONFIG
    with open("config.json") as config_f:

        config.update(json.load(config_f))

    # Create the date here to avoid race condition on day rollover
    the_now = datetime.datetime.now()
    workdir=sync_files(config["host"])
    print "Backup dir is %s" % workdir
    file_list = get_files(workdir, config["backup_root"])
    clean_files(config["host"], config["user"], file_list, the_now)
